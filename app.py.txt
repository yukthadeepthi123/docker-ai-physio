import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import json
from datetime import datetime

# Initialize MediaPipe
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

st.title("Docker AI Physiotherapy Assistant (Video Demo)")

# Upload exercise video
uploaded_file = st.file_uploader("Upload Exercise Video", type=["mp4", "avi"])

if uploaded_file:
    try:
        # Save uploaded video temporarily
        tfile = "demo_video.mp4"
        with open(tfile, "wb") as f:
            f.write(uploaded_file.read())

        # Initialize video capture
        cap = cv2.VideoCapture(tfile)
        if not cap.isOpened():
            st.error("Error: Could not open video file.")
            st.stop()

        # Initialize MediaPipe Pose
        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
            data_log = []
            stframe = st.empty()
            progress_bar = st.progress(0)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            for frame_idx in range(total_frames):
                ret, frame = cap.read()
                if not ret:
                    break

                # Convert BGR to RGB
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image)

                # Convert back to BGR for OpenCV
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

                feedback = "No pose detected"
                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

                    # Right arm angle calculation
                    right_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]
                    right_elbow = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW]
                    right_wrist = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]

                    a = np.array([right_shoulder.x, right_shoulder.y])
                    b = np.array([right_elbow.x, right_elbow.y])
                    c = np.array([right_wrist.x, right_wrist.y])

                    ba = a - b
                    bc = c - b
                    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
                    angle = np.arccos(cosine_angle)
                    angle_deg = np.degrees(angle)

                    # Enhanced feedback
                    if angle_deg < 140:
                        feedback = "Raise your arm higher for better form!"
                    elif angle_deg > 170:
                        feedback = "Lower your arm slightly to avoid strain!"
                    else:
                        feedback = "Perfect arm position! Keep it up!"

                    # Log data
                    data_log.append({
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "right_arm_angle": angle_deg,
                        "feedback": feedback
                    })

                # Display frame and feedback
                stframe.image(image, channels="BGR")
                st.text(f"Feedback: {feedback}")

                # Update progress
                progress_bar.progress((frame_idx + 1) / total_frames)

        # Release video capture
        cap.release()

        # Save log
        with open("exercise_log.json", "w") as f:
            json.dump(data_log, f, indent=4)

        st.success("Demo finished! Log saved to exercise_log.json")

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")

else:
    st.info("Please upload a video to start the demo.")
